{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e37ef6",
   "metadata": {},
   "source": [
    "# Proyecto: Informe de Emails Recibidos\n",
    "\n",
    "\n",
    "## Introducci√≥n\n",
    "\n",
    "### Problema a abordar\n",
    "\n",
    "La problem√°tica radica en la gran cantidad de mails que recibimos todos los d√≠as. En esa marea de mails, se suelen pasar por alto mails importantes. Muchas veces, un mail queda perdido en el buz√≥n de entrada y luego se hace dif√≠cil encontrarlo. Si adem√°s se refer√≠a a algo urgente que necesitaba verse a tiempo, se torna un problema mayor.\n",
    "\n",
    "### Desarrollo de la propuesta de soluci√≥n\n",
    "\n",
    "La propuesta es generar un informe de env√≠o semanal a una casilla de correo que haga un repaso de todos los mails recibidos en la √∫ltima semana, de manera que nos permita ponernos al d√≠a con los asuntos a atender. Se buscar√° que el informe ordene los temas relevados seg√∫n orden de prioridad.<br>\n",
    "La idea consiste en acceder a un mail en Outlook o exportar los mails de la √∫ltima semana y a trav√©s de un prompt leer los mails en cuesti√≥n y armar un resumen de estos orden√°ndolos por prioridad.<br>\n",
    "Para usar tambi√©n el modelo texto a imagen, buscaremos que el informe comience con un banner generado por este modelo.\n",
    "\n",
    "\n",
    "\n",
    "**Prompts a utilizar:**\n",
    "\n",
    "- **Texto a Imagen:**\n",
    "\n",
    "```text\n",
    "\n",
    "\"Full-bleed dark gradient analytics banner (blue to purple). \"\n",
    "\"Glowing charts: donut on left, vertical bars center-left, orange line chart across right. \"\n",
    "\"Tiny HUD dots and thin grid lines. Vector, crisp, modern UI, high contrast. \"\n",
    "\"Centered composition with safe padding top and bottom; avoid elements at edges. No text.\"\n",
    "\n",
    "```\n",
    "\n",
    "- **Texto a Texto:**\n",
    "\n",
    "```text\n",
    "\n",
    "ROLE\n",
    "You analyze recent emails and output ONE single artifact: a JSON email draft whose BODY IS the weekly report.\n",
    "\n",
    "METHOD (tight)\n",
    "1) Leer cuidadosamente cada email (asunto, remitente, cuerpo). Extraer datos clave (vencimientos, montos, cuentas, per√≠odos, tickets, links).\n",
    "2) Determinar la acci√≥n necesaria (pagar, responder, adjuntar, confirmar, coordinar, monitorear).\n",
    "3) Organizar y priorizar: primero vencidos/vence hoy; luego pendientes de respuesta; luego seguimiento/colaboraci√≥n; listar todos los NO LE√çDOS.\n",
    "4) Dise√±ar un reporte claro y accionable, resaltando insights/patrones (sin suposiciones). Usar √≠conos y color (HTML) con equivalencia en texto plano.\n",
    "5) Formatear el reporte para env√≠o por email (body_text y body_html equivalentes).\n",
    "6) Devolver el JSON final **y nada m√°s**, cumpliendo el schema.\n",
    "\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Viabilidad del proyecto\n",
    "El proyecto lo podemos dividir en 3 etapas:\n",
    "\n",
    "#### 1) Obtener mails\n",
    "\n",
    "Primero necesitamos tener el contenido de los correos electr√≥nicos recibidos en una casilla de correo. Para esto, se buscar√° acceder a la bandeja de entrada de Outlook o automatizar la exportaci√≥n de los mails de la √∫ltima semana para luego poder entregarle el archivo a Gemini.\n",
    "\n",
    "#### 2) Generar informe\n",
    "\n",
    "La segunda etapa ser√≠a cuando entra en juego el uso de los modelos a trav√©s de las API. Como modelo de texto a texto, se usar√° Gemini para analizar todos los mails y armar el informe. Como modelo de texto a imagen, se buscar√° en Hugging Face alguno gratuito para crear el banner. En esta etapa, se necesitar√° pulir el prompt en ambos modelos para lograr el objetivo.\n",
    "\n",
    "#### 3) Enviar informe\n",
    "\n",
    "La tercera y √∫ltima etapa consiste en enviar por email el informe generado.\n",
    "\n",
    "Las 3 etapas mencionadas son altamente viables de ser llevadas a cabo con las herramientas a disposici√≥n.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Sistematizar la lectura de correos para transformar informaci√≥n dispersa en un informe ejecutivo claro y accionable.\n",
    "\n",
    "Estandarizar criterios de priorizaci√≥n y seguimiento para mejorar la toma de decisiones.\n",
    "\n",
    "## Metodolog√≠a\n",
    "\n",
    "El flujo implementado debe convertir un alto volumen de correos en un producto informativo breve, verificable y anonimizado, apto para lectura ejecutiva y para integrar a tableros/automatizaciones.\n",
    "\n",
    "Las 3 etapas mencionadas se llevan a cabo de la siguiente manera:\n",
    "\n",
    "**Etapa 1: Obtener mails (Recolecci√≥n y depuraci√≥n)**\n",
    "\n",
    "- Obtengo correos desde Microsoft Graph (Outlook) del per√≠odo de an√°lisis y se eliminan duplicidades, ruidos y datos superfluos, preservando la trazabilidad.\n",
    "- Normalizo campos (remitente, asunto, cuerpo, fechas, flags/‚ÄúDestacado‚Äù, adjuntos, webLink). Excluyo correos de promociones, newsletters y enviados por m√≠ salvo que sean relevantes (respuestas a clientes).\n",
    "\n",
    "**Etapa 2: Generar informe (Dise√±o de prompt y orquestaci√≥n)**\n",
    "\n",
    "- Uso instrucciones de sistema claras (rol, estilo, longitud m√°xima, idioma) y secciones obligatorias (urgentes, pendientes, seguimiento y no le√≠dos) para producir un resumen ejecutivo con secciones fijas de menos de 200 palabras.\n",
    "- Aplico anonimizaci√≥n para reemplazar emails y nombres propios por placeholders para poder subirlo a un repositorio publico de Github. \n",
    "\n",
    "\n",
    "**Etapa 3: Enviar Informe**\n",
    "\n",
    "- Genero informe resumen seg√∫n el formato buscado y lo env√≠o en un mail a la misma casilla de correo de donde se obtuvieron los correos relevados.\n",
    "\n",
    "## Herramientas y tecnolog√≠as\n",
    "\n",
    "Se utilizan:\n",
    "- Visual Studio Code\n",
    "- Jupyter Notebook\n",
    "- Github\n",
    "\n",
    "- Lenguaje: **Python**\n",
    "- Modelo AI: **Google Gemini**, **Flux.1 Schnell** \n",
    "\n",
    "**Tecnica de Prompt:**\n",
    "\n",
    "Se busca utilizar en primera instancia la tecnica zero-shot para no incrementar el alto consumo de tokens que se prevee. La cantidad de tokens va a ser alta de por s√≠ por la cantidad de correos que tiene que analizar el modelo. Sumado a eso, en funcion de obtener el resultado deseado, el prompt va a requerir un mayor detalle y, por ende, una cantidad importante de tokens. Aunque se trata de optimizar el consumo de tokens, se evaluar√° si el resultado obtenido es acorde a lo esperado y, en caso de no serlo, se optar√° por agregar ejemplos (few-shot) para obtener respuestas breves y bien formateadas.\n",
    "\n",
    "## Implementaci√≥n\n",
    "\n",
    "A continuaci√≥n se incluye el c√≥digo para llegar a la soluci√≥n propuesta:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ffcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generado con: black-forest-labs/FLUX.1-schnell\n"
     ]
    }
   ],
   "source": [
    "# ===== Generacion de banner : uso de modelo texto a imagen =====\n",
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image, ImageFilter\n",
    "from pathlib import Path\n",
    "\n",
    "ASSETS = Path(\"assets\"); ASSETS.mkdir(exist_ok=True)\n",
    "BANNER_PATH = ASSETS / \"banner.png\"   # ruta fija\n",
    "\n",
    "\n",
    "# Tama√±os\n",
    "FINAL_W, FINAL_H = 1400, 120      # exactamente el espacio del reporte\n",
    "GEN_W, GEN_H     = 1024, 240      # m√°s alto para mejor detalle (no se recorta)\n",
    "\n",
    "# Modelos: probamos otro y dejamos sdxl-turbo como fallback\n",
    "MODELS = [\n",
    "    \"black-forest-labs/FLUX.1-schnell\",   # r√°pido, buenos banners\n",
    "    \"stabilityai/sdxl-turbo\",             # fallback r√°pido\n",
    "]\n",
    "\n",
    "# Prompt: estilo similar al ejemplo, sin texto/etiquetas/axes\n",
    "PROMPT = (\n",
    "    \"Full-bleed dark gradient analytics banner (blue to purple). \"\n",
    "    \"Glowing charts: donut on left, vertical bars center-left, orange line chart across right. \"\n",
    "    \"Tiny HUD dots and thin grid lines. Vector, crisp, modern UI, high contrast. \"\n",
    "    \"Centered composition with safe padding top and bottom; avoid elements at edges. No text.\"\n",
    ")\n",
    "NEGATIVE = (\n",
    "    \"text, words, letters, numbers, digits, labels, captions, watermark, logo, axis, axes, \"\n",
    "    \"ticks, scale marks, frame, border, people, hands, blurry, lowres, artifacts\"\n",
    ")\n",
    "\n",
    "STEPS    = 9           # 8‚Äì12 va bien\n",
    "GUIDANCE = 0.0\n",
    "SEED     = 1337        # cambi√° para otra variaci√≥n\n",
    "\n",
    "def make_client(model_id: str, token: str) -> InferenceClient:\n",
    "    # Usamos provider de la Hosted Inference API para evitar el 'auto'\n",
    "    return InferenceClient(model=model_id, provider=\"hf-inference\", api_key=token)\n",
    "\n",
    "def generate(model_id: str, token: str) -> Image.Image:\n",
    "    client = make_client(model_id, token)\n",
    "    return client.text_to_image(\n",
    "        prompt=PROMPT,\n",
    "        negative_prompt=NEGATIVE,\n",
    "        width=GEN_W,\n",
    "        height=GEN_H,\n",
    "        num_inference_steps=STEPS,\n",
    "        guidance_scale=GUIDANCE,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    load_dotenv()\n",
    "    token = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "    assert token, \"Falta HUGGINGFACE_API_KEY en .env\"\n",
    "\n",
    "    img = None\n",
    "    last_err = None\n",
    "    for mid in MODELS:\n",
    "        try:\n",
    "            img = generate(mid, token)\n",
    "            print(f\"‚úÖ Generado con: {mid}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Fall√≥ {mid}: {e!r}\")\n",
    "            last_err = e\n",
    "\n",
    "    if img is None:\n",
    "        raise RuntimeError(f\"No se pudo generar ninguna imagen. √öltimo error: {last_err!r}\")\n",
    "\n",
    "    # Solo reescalar (sin recortar) al tama√±o exacto del banner\n",
    "    banner = img.resize((FINAL_W, FINAL_H), Image.LANCZOS)\n",
    "    banner = banner.filter(ImageFilter.UnsharpMask(radius=0.5, percent=70, threshold=2))\n",
    "\n",
    "    banner.save(BANNER_PATH, format=\"PNG\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "574bca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Informe generado correctamente\n"
     ]
    }
   ],
   "source": [
    "# ===== Generacion del informe: uso del modelo de texto a texto =====\n",
    "\n",
    "import os, json, re\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types  # <- para GenerateContentConfig\n",
    "from pathlib import Path\n",
    "\n",
    "# Fecha con zona horaria AR\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo  # Python 3.9+\n",
    "except Exception:\n",
    "    ZoneInfo = None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "load_dotenv()\n",
    "\n",
    "#_MODEL_ENV = os.getenv(\"GOOGLE_GEMINI_MODEL\", \"gemini-2.5-flash\")\n",
    "_MODEL_ENV = os.getenv(\"GOOGLE_GEMINI_MODEL\", \"gemini-2.5-pro\")\n",
    "MODEL = _MODEL_ENV.replace(\"models/\", \"\")\n",
    "# El cliente toma GEMINI_API_KEY o GOOGLE_API_KEY desde el entorno\n",
    "client = genai.Client()\n",
    "\n",
    "# mails a enviar copia\n",
    "EMAIL_REPORT_CC= \"\"\n",
    "EMAIL_REPORT_BCC=\"\"\n",
    "\n",
    "# banner path\n",
    "ASSETS_DIR = Path(\"assets\")\n",
    "BANNER_PATH = ASSETS_DIR / \"banner.png\"\n",
    "\n",
    "# === Config √∫nica (editar solo ac√°) ===\n",
    "CONFIG = {\n",
    "    \"from_mailreader\": True,\n",
    "    \"limit\": 1000, #limite de mails a buscar\n",
    "    \"days_back\": 30, #cantidad de dias hacia atras para buscar mails\n",
    "    \"json_path\": None,\n",
    "    \"max_chars\": 120_000, # maxima cantidad de caracteres a mandar al modelo\n",
    "    \"out\": None,                 # \"respuesta.txt\" o None\n",
    "    \"model\": MODEL,              # o \"gemini-2.5-pro\", etc.\n",
    "    \"temperature\": None,         # ej. 0,3\n",
    "    \"max_output_tokens\": None,   # ej. 1200\n",
    "    \"response_mime_type\": \"application/json\",  # ej. \"text/markdown\"\n",
    "    \"debug\": False,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Response schema (EMAIL ONLY)\n",
    "# =========================\n",
    "EMAIL_ONLY_SCHEMA = types.Schema(\n",
    "  type=types.Type.OBJECT,\n",
    "  properties={\n",
    "    \"email_draft\": types.Schema(\n",
    "      type=types.Type.OBJECT,\n",
    "      properties={\n",
    "        \"body_text\":types.Schema(type=types.Type.STRING),\n",
    "        \"body_html\":types.Schema(type=types.Type.STRING),\n",
    "      },\n",
    "      required=[\"body_text\",\"body_html\"]\n",
    "    )\n",
    "  },\n",
    "  required=[\"email_draft\"]\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "\n",
    "def load_rows_from_json(path: str) -> tuple[list[dict], str | None]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if isinstance(data, dict) and \"rows\" in data:\n",
    "        rows = data[\"rows\"]\n",
    "    elif isinstance(data, list):\n",
    "        rows = data\n",
    "    else:\n",
    "        raise ValueError(\"El JSON no es una lista de correos.\")\n",
    "    return rows, None\n",
    "\n",
    "def load_rows_from_mailreader(limit: int | None = None, days_back: int | None = None) -> tuple[list[dict], str]:\n",
    "    \"\"\"\n",
    "    Lee correos con mail_reader y, en la misma funci√≥n, obtiene la casilla actual desde Graph /me.\n",
    "    Devuelve (rows, my_email). Si no hay casilla, falla.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import mail_reader as mr\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"No pude importar mail_reader: {e}\")\n",
    "\n",
    "    # === 1) Leer correos ===\n",
    "    if hasattr(mr, \"collect_rows\"):\n",
    "        try:\n",
    "            rows = mr.collect_rows(limit=limit, days_back=days_back or None, debug=False)\n",
    "        except TypeError:\n",
    "            rows = mr.collect_rows(limit=limit)\n",
    "    elif hasattr(mr, \"main\"):\n",
    "        out_path = os.getenv(\"OUTPUT_JSON\", \"emails.json\")\n",
    "        mr.main()\n",
    "        rows = load_rows_from_json(out_path)[0]  # nuestra load_rows_from_json ahora devuelve (rows, None)\n",
    "    else:\n",
    "        raise RuntimeError(\"mailreader no expone collect_rows() ni main().\")\n",
    "\n",
    "    # === 2) Resolver casilla via Graph /me (mismo token/cach√© del mailreader) ===\n",
    "    client_id = getattr(mr, \"CLIENT_ID\", None) or os.getenv(\"CLIENT_ID\")\n",
    "    tenant_id = getattr(mr, \"TENANT_ID\", None) or os.getenv(\"TENANT_ID\", \"common\")\n",
    "    if not client_id:\n",
    "        raise RuntimeError(\"CLIENT_ID no definido en mail_reader ni en variables de entorno.\")\n",
    "\n",
    "    app, persist_cache = mr.build_msal_app(client_id, tenant_id)\n",
    "    token = mr.acquire_token(app, persist_cache)\n",
    "    access_token = token.get(\"access_token\")\n",
    "    if not access_token:\n",
    "        raise RuntimeError(\"No se obtuvo access_token para Microsoft Graph.\")\n",
    "\n",
    "    me = mr.graph_get(\n",
    "        f\"{mr.GRAPH}/me\",\n",
    "        access_token,\n",
    "        params={\"$select\": \"mail,userPrincipalName,otherMails\"}\n",
    "    )\n",
    "\n",
    "    my_email = None\n",
    "    for k in (\"mail\", \"userPrincipalName\"):\n",
    "        v = (me.get(k) or \"\").strip()\n",
    "        if \"@\" in v:\n",
    "            my_email = v\n",
    "            break\n",
    "    if not my_email:\n",
    "        for v in (me.get(\"otherMails\") or []):\n",
    "            v = (v or \"\").strip()\n",
    "            if \"@\" in v:\n",
    "                my_email = v\n",
    "                break\n",
    "\n",
    "    # Fallback final: helper del m√≥dulo si existe\n",
    "    if not my_email and hasattr(mr, \"get_my_addresses\"):\n",
    "        try:\n",
    "            addrs = mr.get_my_addresses(access_token) or []\n",
    "            for v in addrs:\n",
    "                if isinstance(v, str) and \"@\" in v:\n",
    "                    my_email = v.strip()\n",
    "                    break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if not my_email:\n",
    "        raise RuntimeError(\"No se pudo determinar la casilla desde Graph /me (mail/userPrincipalName/otherMails).\")\n",
    "\n",
    "    return rows, my_email\n",
    "\n",
    "## Banner\n",
    "def _banner_block() -> str:\n",
    "    \"\"\"Devuelve el <img> inline (base64) si existe assets/banner.png, o '' si no existe.\"\"\"\n",
    "    try:\n",
    "        if BANNER_PATH.exists():\n",
    "            import base64\n",
    "            b64 = base64.b64encode(BANNER_PATH.read_bytes()).decode()\n",
    "            return (\n",
    "                f'<img src=\"data:image/png;base64,{b64}\" '\n",
    "                f'style=\"display:block;width:100%;max-width:900px;height:auto;'\n",
    "                f'border-radius:12px;margin:0 0 16px 0;\">'\n",
    "            )\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# === Body reducer / compactor ===\n",
    "# para reducir la cantidad de tokens\n",
    "\n",
    "_SIG_PAT = re.compile(\n",
    "    r\"(?:^--\\s*$|^Enviado desde|^Sent from|^On .+ wrote:|^El .+ escribi√≥:)\",\n",
    "    re.IGNORECASE | re.MULTILINE\n",
    ")\n",
    "_QUOTE_PAT = re.compile(r\"^\\s*>.*$\", re.MULTILINE)  # l√≠neas citadas tipo '>'\n",
    "_URL_PAT = re.compile(r\"https?://\\S+\")\n",
    "_MULTI_NL = re.compile(r\"\\n{3,}\")\n",
    "\n",
    "def clean_body(txt: str, limit: int = 400) -> str:\n",
    "    if not txt:\n",
    "        return \"\"\n",
    "    # 1) eliminar l√≠neas citadas y URLs\n",
    "    txt = _QUOTE_PAT.sub(\"\", txt)\n",
    "    txt = _URL_PAT.sub(\"\", txt)\n",
    "    # 2) cortar en firma/respuesta previa si aparece\n",
    "    m = _SIG_PAT.search(txt)\n",
    "    if m:\n",
    "        txt = txt[:m.start()]\n",
    "    # 3) colapsar saltos extra y espacios\n",
    "    txt = _MULTI_NL.sub(\"\\n\\n\", txt).strip()\n",
    "    # 4) trunc final\n",
    "    return txt[:limit]\n",
    "\n",
    "\n",
    "def clamp_rows(rows: list[dict], max_chars: int = 120_000) -> list[dict]:\n",
    "    \"\"\"Devuelve filas *compactas* y recorta por caracteres de forma consistente.\"\"\"\n",
    "    compact_rows, total = [], 0\n",
    "    for r in rows:\n",
    "        compact = {\n",
    "            \"Fecha\": r.get(\"Fecha\"),\n",
    "            \"ReceivedUTC\": r.get(\"ReceivedUTC\"),\n",
    "            \"Remitente\": r.get(\"Remitente\"),\n",
    "            \"RemitenteNombre\": r.get(\"RemitenteNombre\"),\n",
    "            \"Asunto\": r.get(\"Asunto\"),\n",
    "            #\"Cuerpo\": (r.get(\"Cuerpo\") or \"\")[:1000],  # l√≠mite duro por mail\n",
    "            \"Cuerpo\": clean_body(r.get(\"Cuerpo\") or \"\", limit=400),  # l√≠mite duro por mail\n",
    "            \"TieneAdjuntos\": bool(r.get(\"TieneAdjuntos\")),\n",
    "            \"Leido\": bool(r.get(\"Leido\")),\n",
    "            \"Respondido\": bool(r.get(\"Respondido\")),\n",
    "            \"Categorias\": r.get(\"Categorias\"),\n",
    "            \"WebLink\": r.get(\"WebLink\"),\n",
    "        }\n",
    "        #s = json.dumps(compact, ensure_ascii=False)\n",
    "        s = json.dumps(compact, ensure_ascii=False, separators=(',', ':'))\n",
    "        \n",
    "        if total + len(s) > max_chars and compact_rows:\n",
    "            break\n",
    "        compact_rows.append(compact)\n",
    "        total += len(s)\n",
    "    return compact_rows\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utils: emails & JSON robusto\n",
    "# =========================\n",
    "\n",
    "_EMAIL_RE = re.compile(r\"[A-Za-z0-9._%+\\-]+@[A-Za-z0-9.\\-]+\\.[A-Za-z]{2,}\")\n",
    "\n",
    "def _split_emails(raw: str) -> list[str]:\n",
    "    if not raw:\n",
    "        return []\n",
    "    # Split por coma, punto y coma, espacios y saltos de l√≠nea\n",
    "    parts = re.split(r\"[,\\s;]+\", raw.strip())\n",
    "    return [p for p in parts if p]\n",
    "\n",
    "def _filter_valid_emails(parts: list[str]) -> list[str]:\n",
    "    return [p for p in parts if _EMAIL_RE.fullmatch(p or \"\")]\n",
    "\n",
    "def _dedupe_preserve_order(items: list[str]) -> list[str]:\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for it in items:\n",
    "        k = it.lower()\n",
    "        if k not in seen:\n",
    "            seen.add(k)\n",
    "            out.append(it)\n",
    "    return out\n",
    "\n",
    "def get_env_cc_bcc() -> tuple[list[str], list[str]]:\n",
    "    cc_raw  = EMAIL_REPORT_CC\n",
    "    bcc_raw = EMAIL_REPORT_BCC\n",
    "\n",
    "    cc  = _dedupe_preserve_order(_filter_valid_emails(_split_emails(cc_raw)))\n",
    "    bcc = _dedupe_preserve_order(_filter_valid_emails(_split_emails(bcc_raw)))\n",
    "    return cc, bcc\n",
    "\n",
    "def extract_json_payload(s: str) -> str:\n",
    "    \"\"\"Intenta extraer el primer bloque JSON { ... } (quita cercos ``` si aparecen).\"\"\"\n",
    "    if not s:\n",
    "        return s\n",
    "    txt = s.strip()\n",
    "    # quitar fences ``` o ```json\n",
    "    if txt.startswith(\"```\"):\n",
    "        txt = re.sub(r\"^```(?:json)?\\s*\", \"\", txt)\n",
    "        txt = re.sub(r\"\\s*```$\", \"\", txt)\n",
    "    # recortar al primer {...} completo\n",
    "    start = txt.find(\"{\")\n",
    "    end   = txt.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        return txt[start:end+1]\n",
    "    return txt\n",
    "\n",
    "_URL_IN_HTML_RE = re.compile(r'(?<!href=[\"\\'])https?://[^\\s<>\"\\']+')\n",
    "\n",
    "def urls_to_anchor_html(html: str) -> str:\n",
    "    html = html or \"\"\n",
    "    return _URL_IN_HTML_RE.sub(lambda m: f'<a href=\"{m.group(0)}\">Ver mail</a>', html)\n",
    "\n",
    "def urls_to_label_text(txt: str) -> str:\n",
    "    txt = txt or \"\"\n",
    "    return re.sub(r'https?://\\S+', 'Ver mail', txt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# System instruction (email-only)\n",
    "# =========================\n",
    "def build_system_instruction(date_from: str) -> str:\n",
    "    return f\"\"\"\n",
    "Title: Weekly Email Report\n",
    "\n",
    "ROLE\n",
    "You analyze recent emails and output ONE single artifact: a JSON email draft whose BODY IS the weekly report.\n",
    "\n",
    "METHOD (tight)\n",
    "1) Leer cuidadosamente cada email (asunto, remitente, cuerpo). Extraer datos clave (vencimientos, montos, cuentas, per√≠odos, tickets, links).\n",
    "2) Determinar la acci√≥n necesaria (pagar, responder, adjuntar, confirmar, coordinar, monitorear).\n",
    "3) Organizar y priorizar: primero vencidos/vence hoy; luego pendientes de respuesta; luego seguimiento/colaboraci√≥n; listar todos los NO LE√çDOS.\n",
    "4) Dise√±ar un reporte claro y accionable, resaltando insights/patrones (sin suposiciones). Usar √≠conos y color (HTML) con equivalencia en texto plano.\n",
    "5) Formatear el reporte para env√≠o por email (body_text y body_html equivalentes).\n",
    "6) Devolver el JSON final **y nada m√°s**, cumpliendo el schema.\n",
    "\n",
    "CONTRACT (STRICT)\n",
    "1) Output = SOLO JSON (sin fences) que cumpla exactamente el schema (abajo).\n",
    "2) Idioma: espa√±ol, tono profesional y conciso.\n",
    "3) Privacidad: reemplazar nombres por [REDACTED], emails por [MAIL] y nombres de empresas por [EMPRESA] en TODO donde aparezcan (asunto, remitente, l√≠neas). \n",
    "4) Enlaces obligatorios: toda l√≠nea que refiera a un email espec√≠fico DEBE incluir su webLink.\n",
    "   - En body_text: mostrar **Ver mail** (no URL cruda).\n",
    "   - En body_html: mostrar **<a href=\"...\">Ver mail</a>** (no URL cruda).\n",
    "5) Sin invenciones: si un dato no est√°, dejar el campo vacio. No inventar montos, fechas ni adjuntos.**Nunca excluir** un correo por faltar un dato secundario.\n",
    "6) Deduplicaci√≥n conservadora por hilo/tema (normalizar asunto quitando ‚ÄúRE:‚Äù/‚ÄúFW:‚Äù y espacios):\n",
    "   - **Solo** deduplicar si los correos no agregan **nueva acci√≥n/fecha/monto**.\n",
    "   - Si hay varias acciones distintas en un mismo hilo, crear **l√≠neas separadas**.\n",
    "   - Excepci√≥n: en **No le√≠dos** no agrupar nunca.\n",
    "7) **Fechas**: formato **DD-MM-YYYY** en todo el cuerpo (incluida la primera l√≠nea y etiquetas de vencimiento).\n",
    "8) **Prioridades (usar √≠conos y color)**\n",
    "   - üî¥ Cr√≠tico (vencido) ‚Üí etiqueta: ‚Äú[atrasado N d√≠as (DD-MM-YYYY)]‚Äù\n",
    "   - üü† Vence hoy ‚Üí etiqueta: ‚Äú[vence hoy DD-MM-YYYY]‚Äù\n",
    "   - üü° Vence en ‚â§3 d√≠as ‚Üí etiqueta: ‚Äú[vence en ‚â§3 d√≠as DD-MM-YYYY]‚Äù\n",
    "   - üü¢ Informativo/menor (seguimiento)\n",
    "9) Cada l√≠nea puede incluir **nota** (8-25 palabras) y, si corresponde, **pr√≥ximo paso** o **impacto** expl√≠citos.\n",
    "10) **Cobertura**: incluir **todos** los correos **no-newsletter**. Si el texto se hace largo, **mantener todos los √≠tems** y acortar la ‚Äúnota‚Äù.\n",
    "\n",
    "OUTPUT SCHEMA (email-only)\n",
    "{{\n",
    "  \"email_draft\": {{\n",
    "    \"body_text\": \"string\",\n",
    "    \"body_html\": \"string\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "RESTRICCI√ìN\n",
    "- NO incluyas \"to\", \"cc\", \"bcc\" ni \"subject\".\n",
    "\n",
    "BODY TEMPLATE (NO imprimas ‚ÄúEncabezado‚Äù literalmente)\n",
    "- L√≠nea de contexto (primera l√≠nea):\n",
    "Resumen del correo electr√≥nico recibido desde el d√≠a **{date_from}** hasta la fecha.\n",
    "\n",
    "- L√≠nea de conteo (una sola l√≠nea):\n",
    "‚è∞ Urgencias: X ¬∑ üß© Acciones pendientes: Y ¬∑ üì® No le√≠dos: Z\n",
    "\n",
    "- **Asuntos Urgentes y Vencimientos Cr√≠ticos (Atenci√≥n Inmediata)**\n",
    "(orden: vencidos ‚Üí hoy ‚Üí ‚â§3 d√≠as; deduplicados por tema)\n",
    "‚Ä¢ üî¥ [atrasado N d√≠as (DD-MM-YYYY)] Asunto normalizado ‚Äî **Acci√≥n:** ‚Ä¶ ‚Äî nota: (8-25 palabras) - link: Ver mail (+N similares)\n",
    "‚Ä¢ üü† [vence hoy DD-MM-YYYY] Asunto normalizado ‚Äî **Acci√≥n:** ‚Ä¶ ‚Äî nota: ‚Ä¶ ‚Äî link: Ver mail\n",
    "‚Ä¢ üü° [vence en ‚â§3 d√≠as DD-MM-YYYY] Asunto normalizado ‚Äî **Acci√≥n:** ‚Ä¶ ‚Äî nota: ‚Ä¶ ‚Äî link: Ver mail\n",
    "\n",
    "- **Acciones Pendientes**\n",
    "(solicitudes expl√≠citas que requieren tu respuesta/confirmaci√≥n y a√∫n no fueron respondidas)\n",
    "‚Ä¢ üß© Asunto normalizado ‚Äî **Acci√≥n:** ‚Ä¶ ‚Äî nota: (qu√© pide/qu√© falta) ‚Äî link: Ver mail\n",
    "\n",
    "- **Tareas de Seguimiento y Colaboraci√≥n**\n",
    "(temas en curso que no son urgencia ni pedido directo, no incluir newsletters)\n",
    "‚Ä¢ üü¢ T√≥pico/tema ‚Äî **Pr√≥ximo paso:** ‚Ä¶ ‚Äî nota: (monto, banco, cuenta, ticket, per√≠odo) ‚Äî link: Ver mail\n",
    "\n",
    "- **No le√≠dos**\n",
    "(listar absolutamente **todos** los correos con Leido == false; m√°s recientes primero; SIN agrupar)\n",
    "‚Ä¢ üì® Asunto normalizado ‚Äî Remitente [REDACTED] ‚Äî nota: (frase breve del cuerpo) ‚Äî link: Ver mail\n",
    "(Si el volumen excede el l√≠mite, mostrar los que entren y cerrar con ‚Äú+N restantes‚Äù.)\n",
    "\n",
    "CLASSIFICATION RULES\n",
    "- Urgente/cr√≠tico: due_date <= hoy o cuerpo con ‚Äúvencido‚Äù, ‚Äúvence hoy‚Äù, ‚Äú√∫ltimo aviso‚Äù, etc.\n",
    "- Pendiente: pedidos directos (‚Äú¬øpod√©s‚Ä¶?‚Äù, ‚Äúpor favor envi√°‚Ä¶‚Äù, ‚Äúnecesito‚Ä¶‚Äù) sin respuesta.\n",
    "- Seguimiento/colaboraci√≥n: temas en curso que no son urgencia ni pedido directo, pero requieren coordinaci√≥n (reuniones, tickets, configuraciones, informes).\n",
    "- No le√≠dos: TODOS los Leido == false del dataset (sin agrupar).\n",
    "- Si detect√°s varios emails del mismo tema, deduplicar con ‚Äú(+N similares)‚Äù excepto en No le√≠dos.\n",
    "- Excluir unicamente **Newsletter/FYI**\n",
    "- No repetir emails en las distintas secciones. Ubicar cada email en la seccion m√°s apropiada. Si Leido = false, va en la seccion **No le√≠dos**.\n",
    "\n",
    "\n",
    "HTML REQUIREMENTS\n",
    "- `body_html` equivalente a `body_text`; permitido: <div>, <p>, <strong>, <ul>, <li>, <a>, <span>, <hr>, <img>.\n",
    "- √çconos Unicode (üî¥ üü† üü° üü¢ ‚è∞ üß© ü§ù üì® ‚ö†Ô∏è üìä üìé) y color en <span style=\"...\">.\n",
    "- Incluir banner superior (placeholder):\n",
    "  <div style=\"width:100%;height:120px;background:#0F172A;border-radius:8px;margin:0 0 16px 0;\"></div>\n",
    "\n",
    "VALIDATION\n",
    "- Si una secci√≥n no puede completarse sin adivinar, omitirla por completo.\n",
    "- Todos los nombres de personas de personas se deben reemplazar nombres por [REDACTED], los emails por [MAIL] y las empresas por [EMPRESA].\n",
    "- Devolver SOLO el JSON con `email_draft`, sin texto extra.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Build user contents\n",
    "# =========================\n",
    "def build_contents(rows: list[dict]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list[str] with the payload (SDK turns each into UserContent).\n",
    "    We serialize each email row as a compact JSON line and split into blocks.\n",
    "    \"\"\"\n",
    "    intro = \"Below is the mailing list in compact JSON lines:\"\n",
    "    #Serializamos cada correo en una l√≠nea compacta\n",
    "    lines = [json.dumps(r, ensure_ascii=False, separators=(',', ':')) for r in rows]\n",
    "    #Partimos en bloques de 30 l√≠neas para que no sea una sola cadena enorme \n",
    "    BATCH = 30\n",
    "    blocks = [\"\\n\".join(lines[i:i+BATCH]) for i in range(0, len(lines), BATCH)]\n",
    "    return [intro] + blocks\n",
    "\n",
    "\n",
    "# Robustly extract JSON from GEMINI response\n",
    "def extract_json_from_response(resp) -> str:\n",
    "    \"\"\"\n",
    "    Try multiple places where the JSON can live in the Google GenAI response.\n",
    "    Falls back to '', never raises.\n",
    "    \"\"\"\n",
    "    # 1) Fast path: aggregated text\n",
    "    try:\n",
    "        txt = getattr(resp, \"text\", None)\n",
    "        if txt and txt.strip():\n",
    "            return txt\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Candidates/parts: text or inline_data (base64) with application/json\n",
    "    try:\n",
    "        cands = getattr(resp, \"candidates\", None) or []\n",
    "        for c in cands:\n",
    "            content = getattr(c, \"content\", None)\n",
    "            parts = getattr(content, \"parts\", None) or []\n",
    "            for p in parts:\n",
    "                # Plain text\n",
    "                if hasattr(p, \"text\") and p.text:\n",
    "                    return p.text\n",
    "                # Inline JSON blob\n",
    "                inline = getattr(p, \"inline_data\", None)\n",
    "                if inline and getattr(inline, \"mime_type\", \"\") == \"application/json\":\n",
    "                    b64 = getattr(inline, \"data\", \"\") or \"\"\n",
    "                    if b64:\n",
    "                        import base64\n",
    "                        try:\n",
    "                            return base64.b64decode(b64).decode(\"utf-8\", \"ignore\")\n",
    "                        except Exception:\n",
    "                            pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "# =========================\n",
    "# Ejecutor\n",
    "# =========================\n",
    "def run_analysis(config: dict):\n",
    "    \"\"\"Ejecuta el an√°lisis leyendo TODO de config.\"\"\"\n",
    "    from_mailreader     = config[\"from_mailreader\"]\n",
    "    limit               = config[\"limit\"]\n",
    "    days_back           = config[\"days_back\"]\n",
    "    json_path           = config[\"json_path\"]\n",
    "    max_chars           = config[\"max_chars\"]\n",
    "    out                 = config[\"out\"]\n",
    "    model               = (config[\"model\"] or MODEL).replace(\"models/\", \"\")\n",
    "    temperature         = config[\"temperature\"]\n",
    "    max_output_tokens   = config[\"max_output_tokens\"]\n",
    "    response_mime_type  = config[\"response_mime_type\"]\n",
    "    debug               = config[\"debug\"]\n",
    "\n",
    "    # Zona horaria AR\n",
    "    if ZoneInfo:\n",
    "        now_ar = datetime.now(ZoneInfo(\"America/Argentina/Buenos_Aires\"))\n",
    "    else:\n",
    "        now_ar = datetime.now()\n",
    "\n",
    "    date_from = (now_ar - timedelta(days=days_back)).strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    # 1) Carga de correos\n",
    "    if from_mailreader:\n",
    "        rows, my_email = load_rows_from_mailreader(limit=limit, days_back=days_back)\n",
    "    else:\n",
    "        jp = json_path or os.getenv(\"OUTPUT_JSON\", \"emails.json\")\n",
    "        rows, my_email = load_rows_from_json(jp)\n",
    "\n",
    "    if not rows:\n",
    "        return \"\", {\"error\": \"No hay correos para analizar.\"}\n",
    "    if from_mailreader and not my_email:\n",
    "        return \"\", {\"error\": \"No se pudo resolver la casilla desde mailreader/Graph.\"}\n",
    "\n",
    "    # Log de informaci√≥n\n",
    "    #print(f\"Correos cargados: {len(rows)}\")\n",
    "    #print(f\"Email del usuario: {my_email}\")\n",
    "    #print(f\"Per√≠odo: √∫ltimos {days_back} d√≠as desde {date_from}\")\n",
    "    \n",
    "\n",
    "    # 2) Orden + recorte\n",
    "    rows_sorted  = sorted(rows, key=lambda r: r.get(\"ReceivedUTC\") or r.get(\"Fecha\") or \"\", reverse=True)\n",
    "    rows_compact = clamp_rows(rows_sorted, max_chars=max_chars)\n",
    "\n",
    "    # 3) Prompt: System + contents\n",
    "    system_instruction = build_system_instruction(date_from)\n",
    "    contents = build_contents(rows_compact)\n",
    "\n",
    "    # 3.bis) Conteo simple SIN usar system_instruction en config\n",
    "    def _tok(res):\n",
    "        return getattr(res, \"total_tokens\", None) or getattr(res, \"total_tokens_count\", 0)\n",
    "\n",
    "    # tokens SOLO del system: lo contamos como si fuera el primer contenido\n",
    "    t_system_only = _tok(client.models.count_tokens(\n",
    "        model=model,\n",
    "        contents=[system_instruction]\n",
    "    ))\n",
    "\n",
    "    # tokens TOTALES de entrada: system + contents reales (intro + JSON)\n",
    "    t_input_total = _tok(client.models.count_tokens(\n",
    "        model=model,\n",
    "        contents=[system_instruction] + contents\n",
    "    ))\n",
    "\n",
    "    # tokens de correos ‚âà total - system\n",
    "    t_emails_est = max(t_input_total - t_system_only, 0)\n",
    "\n",
    "\n",
    "    # 4) Llamada al modelo\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=system_instruction,\n",
    "                response_mime_type=response_mime_type if response_mime_type else None,\n",
    "                response_schema=EMAIL_ONLY_SCHEMA,\n",
    "                max_output_tokens=max_output_tokens if max_output_tokens else None,\n",
    "                temperature=temperature if temperature else None, \n",
    "            ),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            raise\n",
    "        return \"\", {\"error\": f\"Fallo generate_content: {e}\", \"model\": model}\n",
    "    \n",
    "    # 4.bis) Extraer JSON de forma robusta\n",
    "    raw_payload = extract_json_from_response(response)\n",
    "    text_for_json = extract_json_payload(raw_payload)\n",
    "\n",
    "    if not text_for_json or not text_for_json.strip():\n",
    "        return \"\", {\n",
    "            \"error\": \"El modelo no devolvio JSON valido (payload vacio).\",\n",
    "            \"model\": model,\n",
    "            \"rows_after_clamp\": len(rows_compact),\n",
    "            \"raw_excerpt\": (raw_payload or \"\")[:600]\n",
    "        }\n",
    "\n",
    "    #raw_text = getattr(response, \"text\", \"\") or \"\"\n",
    "    #text_for_json = extract_json_payload(raw_text)\n",
    "\n",
    "    # 5) Post-proceso determinista: fijar destinatario, subject y CC/BCC\n",
    "    try:\n",
    "        data = json.loads(text_for_json)\n",
    "        if not isinstance(data, dict) or \"email_draft\" not in data:\n",
    "            raise ValueError(\"Respuesta inv√°lida: falta 'email_draft'.\")\n",
    "        draft = data[\"email_draft\"]\n",
    "        if not isinstance(draft, dict):\n",
    "            raise ValueError(\"'email_draft' no es objeto.\")\n",
    "        # Subject est√°ndar (AR)\n",
    "        if ZoneInfo:\n",
    "            today_ar = datetime.now(ZoneInfo(\"America/Argentina/Buenos_Aires\")).strftime(\"%d-%m-%Y\")\n",
    "        else:\n",
    "            # Fallback sin zona (solo si tu runtime no tiene zoneinfo)\n",
    "            today_ar = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "\n",
    "        # TO (Graph) + SUBJECT fijo\n",
    "        to_list  = [my_email] if my_email else []\n",
    "        draft[\"to\"] = to_list\n",
    "        draft[\"subject\"] = f\"Reporte semanal ‚Äî {today_ar}\"\n",
    "\n",
    "        \n",
    "        # CC/BCC desde .env (dedup vs TO)\n",
    "        cc_list, bcc_list = get_env_cc_bcc()\n",
    "        to_lwr = {e.lower() for e in to_list}\n",
    "\n",
    "        cc_final  = [e for e in cc_list  if e.lower() not in to_lwr]\n",
    "        bcc_final = [e for e in bcc_list if e.lower() not in to_lwr]\n",
    "\n",
    "        if cc_final:  draft[\"cc\"]  = cc_final\n",
    "        if bcc_final: draft[\"bcc\"] = bcc_final\n",
    "\n",
    "        # Normalizar links\n",
    "        draft[\"body_html\"] = urls_to_anchor_html(draft.get(\"body_html\"))\n",
    "        draft[\"body_text\"] = urls_to_label_text(draft.get(\"body_text\"))\n",
    "\n",
    "        # Insertar banner real arriba del body_html (y quitar placeholder si vino del modelo)\n",
    "        placeholder = '<div style=\"width:100%;height:120px;background:#0F172A;border-radius:8px;margin:0 0 16px 0;\"></div>'\n",
    "        if \"body_html\" in draft and draft[\"body_html\"]:\n",
    "            draft[\"body_html\"] = draft[\"body_html\"].replace(placeholder, \"\", 1)\n",
    "\n",
    "        banner_html = _banner_block()\n",
    "        if banner_html:\n",
    "            draft[\"body_html\"] = banner_html + (draft.get(\"body_html\") or \"\")\n",
    "\n",
    "\n",
    "\n",
    "        # Re-serializar la respuesta ya corregida\n",
    "        text = json.dumps(data, ensure_ascii=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            raise\n",
    "        # devolvemos el texto crudo y la advertencia\n",
    "        return \"\", {\n",
    "            \"error\": f\"No pude post-procesar  JSOON de salida: {e}\",\n",
    "            \"model\": model,\n",
    "            \"raw_excerpt\": text_for_json[:600]\n",
    "        }\n",
    "\n",
    "    # 6) Guardado opcional\n",
    "    saved_path = None\n",
    "    if out:\n",
    "        saved_path = os.path.abspath(out)\n",
    "        with open(out, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "    # 7) M√©tricas de uso\n",
    "    usage = {}\n",
    "    if hasattr(response, \"usage_metadata\") and response.usage_metadata:\n",
    "        u = response.usage_metadata\n",
    "        usage = {\n",
    "            \"prompt_tokens\": getattr(u, \"prompt_token_count\", None),\n",
    "            \"response_tokens\": getattr(u, \"candidates_token_count\", None),\n",
    "            \"thoughts_tokens\": getattr(u, \"thoughts_token_count\", None),\n",
    "            \"total_tokens\": getattr(u, \"total_token_count\", None),\n",
    "        }\n",
    "\n",
    "    meta = {\n",
    "        \"model\": model,\n",
    "        \"saved_to\": saved_path,\n",
    "        \"usage\": usage,\n",
    "        \"rows_in\": len(rows),\n",
    "        \"rows_after_clamp\": len(rows_compact),\n",
    "        \"system_tokens_est\": t_system_only,\n",
    "        \"emails_tokens_est\": t_emails_est,\n",
    "        \"input_total_tokens_est\": t_input_total,\n",
    "\n",
    "    }\n",
    "    return text, meta\n",
    "\n",
    "# =========================\n",
    "# Invocaci√≥n\n",
    "# =========================\n",
    "texto, meta = run_analysis(CONFIG)\n",
    "\n",
    "if not texto or not texto.strip():\n",
    "    print(\"No se obtuvo JSON decodificable. \\nDetalles meta:\", meta)\n",
    "else:\n",
    "    try:\n",
    "        data = json.loads(texto)\n",
    "        draft = data[\"email_draft\"]\n",
    "        print(f\"‚úÖ Informe generado correctamente\")\n",
    "        #print(\"Subject:\", draft.get(\"subject\", \"\"))\n",
    "        #print(\"To:\", \", \".join(draft.get(\"to\", [])))\n",
    "        #print(\"CC:\", \", \".join(draft.get(\"cc\", [])))\n",
    "        #print(\"BCC:\", \", \".join(draft.get(\"bcc\", [])))\n",
    "        #print(texto)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSONDecodeError al parsear la salida.\\nMeta:\", meta)\n",
    "        #print(\"\\nTexto(primeros 600 chars):\", (texto or \"\")[:600])\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff5ed5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HTML preview in 'previews' folder: email_preview.html\n"
     ]
    }
   ],
   "source": [
    "# ===== Guardar HTML Preview =====\n",
    "import json, html, os\n",
    "from pathlib import Path\n",
    "\n",
    "model_output_str = texto\n",
    "\n",
    "# 2) Parseo y obtenci√≥n de campos\n",
    "data = json.loads(model_output_str)\n",
    "draft = data.get(\"email_draft\", {}) if isinstance(data, dict) else {}\n",
    "subject = (draft.get(\"subject\") or \"Reporte semanal\").strip()\n",
    "body_html = (draft.get(\"body_html\") or \"\").strip()\n",
    "body_text = (draft.get(\"body_text\") or \"\").strip()\n",
    "\n",
    "# 3) Fallback: si no hay body_html, convertir body_text a HTML b√°sico\n",
    "if not body_html and body_text:\n",
    "    body_html = \"<p>\" + html.escape(body_text).replace(\"\\n\\n\", \"</p><p>\").replace(\"\\n\", \"<br>\") + \"</p>\"\n",
    "if not body_html:\n",
    "    body_html = \"<p>(Sin contenido)</p>\"\n",
    "\n",
    "# 4) Envoltorio HTML simple para email (opcional, se ve prolijo en navegadores)\n",
    "WRAP = f\"\"\"<!doctype html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<title>{html.escape(subject)}</title>\n",
    "<style>\n",
    "  :root {{ --bg:#f4f5f7; --card:#ffffff; --text:#111827; --muted:#6b7280; --border:#e5e7eb; }}\n",
    "  body {{ margin:0; background:var(--bg); color:var(--text); font:16px -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Arial, \"Noto Sans\", \"Helvetica Neue\", sans-serif; }}\n",
    "  .email {{ max-width: 760px; margin: 32px auto; background: var(--card); border: 1px solid var(--border); border-radius: 12px; box-shadow: 0 4px 16px rgba(0,0,0,0.06); overflow: hidden; }}\n",
    "  .header {{ padding: 18px 22px; font-weight: 600; border-bottom: 1px solid var(--border); }}\n",
    "  .content {{ padding: 18px 22px; line-height: 1.55; }}\n",
    "  .content p {{ margin: 0 0 12px; }}\n",
    "  .content ul {{ margin: 0 0 12px 22px; }}\n",
    "  .content li {{ margin: 6px 0; }}\n",
    "  a {{ color: #2563eb; text-decoration: none; }}\n",
    "  a:hover {{ text-decoration: underline; }}\n",
    "  .footer {{ padding: 16px 22px; color: var(--muted); border-top: 1px solid var(--border); font-size: 13px; }}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "  <div class=\"email\">\n",
    "    <div class=\"header\">{html.escape(subject)}</div>\n",
    "    <div class=\"content\">\n",
    "      {body_html}\n",
    "    </div>\n",
    "    <div class=\"footer\">Vista previa exportada ¬∑ El cliente real de correo puede aplicar estilos distintos.</div>\n",
    "  </div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "# 5) Guardar SOLO en disco (sin mostrar)\n",
    "out_dir = Path(os.getenv(\"PREVIEW_DIR\", \"./previews\"))\n",
    "out_dir.mkdir(parents=True, exist_ok=True)  # crea ./previews si no existe\n",
    "out_path = out_dir / \"email_preview.html\"\n",
    "out_path.write_text(WRAP, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Saved HTML preview in 'previews' folder: email_preview.html\")\n",
    "\n",
    "#print(f\"Saved preview to: {out_path.resolve()}\")\n",
    "# Si quer√©s abrirlo luego manualmente:\n",
    "# import webbrowser; webbrowser.open(out_path.resolve().as_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b692c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Email enviado: {'ok': True, 'to': ['rizzijp@agromargaritas.com'], 'cc': [], 'bcc': [], 'subject': 'Reporte semanal ‚Äî 16-09-2025'}\n"
     ]
    }
   ],
   "source": [
    "# === Enviar el HTML por correo ===\n",
    "\n",
    "# %pip install -q msal msal-extensions requests python-dotenv\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import importlib, send_email_graph\n",
    "importlib.reload(send_email_graph) #recargar el modulo jupyter\n",
    "\n",
    "# Cargar .env (CLIENT_ID, TENANT_ID)\n",
    "load_dotenv()\n",
    "\n",
    "# Asegurate de que send_email_graph.py est√© en la misma carpeta del notebook (o ajust√° la ruta)\n",
    "HELPER = Path(\"send_email_graph.py\")\n",
    "if not HELPER.exists():\n",
    "    raise FileNotFoundError(\"No encuentro send_email_graph.py en esta carpeta.\")\n",
    "\n",
    "sys.path.append(str(HELPER.resolve().parent))\n",
    "from send_email_graph import send_email_html\n",
    "\n",
    "# draft viene de tu celda anterior:\n",
    "# data = json.loads(texto); draft = data[\"email_draft\"]\n",
    "res = send_email_html(\n",
    "    to=draft.get(\"to\"),\n",
    "    cc=draft.get(\"cc\"),\n",
    "    bcc=draft.get(\"bcc\"),\n",
    "    subject=draft.get(\"subject\"),\n",
    "    body_html=draft.get(\"body_html\"),\n",
    "    save_to_sent=True,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Email enviado:\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c3064",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "La implementacion logra llegar a la soluci√≥n esperada de generar un informe a partir de los emails le√≠dos. Se us√≥ un modelo de texto a imagen para generar el banner del informe. Este luego se sum√≥ al output del modelo de texto a texto para completar el informe.\n",
    "\n",
    "El resultado esperado se logr√≥, aunque considero que sigue habiendo un margen de mejora, especialmente en cuanto al prompt para lograr un informe que sea lo mas adecuado para las necesidades de cada uno. Se intent√≥ estandarizar el formato del informe para que el modelo no presente tanta variabilidad en sus outputs. Aunque no se logra un resultado 100% determinista, el informe sigue ciertos param√©tros que la mayor√≠a de las veces se cumplen dando un resultado m√°s que aceptable. Este es el motivo por el que el prompt termin√≥ siendo mucho mas extenso a lo planteado en un principio. Con mayor tiempo de prueba, en futuras versiones se podr√≠a buscar hacerlo mas eficiente y buscar mejores resultados con menor consumo de tokens. A pesar de que el consumo de tokens termino siendo elevado, principalmente por la cantidad de mails pero tambien por la extension del prompt, se pudieron hacer peque√±os ajustes en el codigo para optimizar este consumo. \n",
    "\n",
    "En cuanto al modelo de imagen Flux.1 Schnell, quiero hacer la salvedad de que se us√≥ √∫nicamente por ser gratuito y para probar el funcionamiento de la implementaci√≥n pero dista mucho de los resultados de los modelos m√°s potentes que existen hoy en el mercado. La realidad es que no har√≠a falta crear el banner cada vez que genera el informe. A los fines de las consignas del proyecto se realiz√≥ de esa manera, aunque no ser√≠a la m√°s eficiente. Aclarado esto, que la generaci√≥n del banner sea parte de la implementaci√≥n permite que tanto el prompt como el modelo se puedan modificar a gusto del usuario.\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "Encar√© este proyecto con la certeza de que era posible llevarlo a cabo pero sin contar con los suficientes conocimientos t√©cnicos de programaci√≥n. Gracias a la posibilidad de usar a la IA como un asistente de punta a punta, sumado a muchas horas de prueba y error, comienzo a experimentar las oportunidades que se empiezan a abrir con el uso de esta tecnolog√≠a. Considero que a√∫n con un resultado que tiene margen de mejora y con un codigo que se puede hacer mucho mas eficiente, el hecho de haber llegado al resultado esperado es m√°s que satisfactorio.\n",
    "\n",
    "M√°s all√° de toda la parte de codigo que requiri√≥ mucho ida y vuelta para lograr el objetivo, quiero destacar la importancia del prompt ya que inici√© el proyecto con uno muy b√°sico y lo fui complejizando a medida que iba viendo los resultados. Dado que los modelos no son deterministas, en la medida que se sigan haciendo pruebas con diferentes emails o casillas de correos, el prompt se deber√≠a seguir puliendo. Asimismo, seg√∫n si es casilla laboral o personal, el rubro en el cual uno trabaje y dem√°s caracter√≠sticas, se podr√≠a customizar para cada caso en particular. En la medida que m√°s se pueda ir adaptando a las necesidades de cada uno, el resultado indefectiblemente va a ir mejorando. Sin embargo, creo que como una primera aproximaci√≥n al uso de este tipo de modelos, el objetivo est√° logrado y sirve de base para ser testeado y mejorado en el futuro. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9c0d3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
